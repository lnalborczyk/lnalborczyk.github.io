{
  "hash": "999334fe2587e36299fde3c243b0888a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Three methods for computing the intra-class correlation in multilevel logistic regression\nauthor: Ladislas Nalborczyk\ndate: 2017-10-08\ncategories:\n  - R\n  - Bayesian\n  - brms\n  - Intra-class correlation\n  - Multilevel regression\ndescription: In the current post, we present and compare three methods of obtaning an estimation of the ICC in multilevel logistic regression models.\n---\n\n::: {.cell}\n\n:::\n\n\nIn a [previous post](../2017-09-22-absenteeism2/2017-09-22-absenteeism2.qmd), we introduced the mutilevel logistic regression model and implemented it in R, using the `brms` package. We tried to predict the presence of students that registered for psychological experiments. We also discussed the use of the *intra-class correlation* (ICC) --also known as the *variance partitioning coefficient* (VPC)--, as a mean to quantifies the proportion of observed variation in the outcome that is attributable to the effect of clustering.\n\nHowever, the computation and the interpretation of the ICC in the context of the logistic regression are not straightforward. In the current post, we will then present and compare three methods of obtaining an estimation of the ICC in multilevel logistic regression models.\n\n## Getting the data\n\nWe will use a dataset contained in the `rethinking` package, which is used and discussed several times in the *Statistical Rethinking* book (McElreath, 2016).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(rethinking)\ndata(UCBadmit)\ndata <- UCBadmit\ndata$gender <- ifelse(data$applicant.gender==\"female\", -0.5, 0.5)\ndata$dept_id <- coerce_index(data$dept)\ndata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   dept applicant.gender admit reject applications gender dept_id\n1     A             male   512    313          825    0.5       1\n2     A           female    89     19          108   -0.5       1\n3     B             male   353    207          560    0.5       2\n4     B           female    17      8           25   -0.5       2\n5     C             male   120    205          325    0.5       3\n6     C           female   202    391          593   -0.5       3\n7     D             male   138    279          417    0.5       4\n8     D           female   131    244          375   -0.5       4\n9     E             male    53    138          191    0.5       5\n10    E           female    94    299          393   -0.5       5\n11    F             male    22    351          373    0.5       6\n12    F           female    24    317          341   -0.5       6\n```\n\n\n:::\n:::\n\n\nThese are graduate school applications to 6 different academic departments at UC Berkeley. The `admit` and the `reject` columns indicate the number of admission and rejections, respectively. The `applications` column is the total nuber of applications (i.e., the sum of `admit` and `reject`). We would like to estimate whether there is a gender bias in admissions.\n\n## Fitting the model\n\nWe will then fit a model that include gender as a predictor, to estimate the associattion between gender and the probability of admission. However, as the probability of admission can vary considerably between departments, and as the number of application of males and females can also vary according to the department, we might want to include a varying intercept by department. Thus, we will estimate the grand mean probability of admission, while still allowing each department to have an independant probability of admission.\n\n$$\n\\begin{aligned}\ny_{i} &\\sim \\mathrm{Binomial}(n_{i}, p_{i}) \\\\\nlogit(p_{i}) &= \\alpha_{dept[i]} + \\beta \\times \\text{gender}_{i}\\\\\n\\alpha_{dept} &\\sim \\mathrm{Normal}(\\alpha, \\tau) \\\\\n\\alpha &\\sim \\mathrm{Normal}(0, 5) \\\\\n\\beta &\\sim \\mathrm{Normal}(0, 5) \\\\\n\\tau &\\sim \\mathrm{HalfCauchy}(0, 5) \\\\\n\\end{aligned}\n$$\n\nAlthough we ignored it in the last post, noteworthy here is that we have to define priors on the log-odds scale... In order to get an intuition of what it means, it might be useful to visualise these priors on both the log-odds scale and the probability scale (i.e., what we are really interested in). To this end, we will use an home-made function called `prior_scales`, that allows to plot priors on both scales.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprior_scales <- function(prior, ...) {\n    \n    library(LaplacesDemon)\n    \n    # extracting the distribution and its arguments\n    prior_type <- get(paste0(\"r\", sub(\"\\\\(.*\", \"\", prior) ) )\n    prior_args <- gsub(\".*\\\\((.*)\\\\).*\", \"\\\\1\", prior)\n    \n    # drawing n samples from the prior\n    n <- 1e6\n    sim <- eval(parse(text = paste(\"prior_type(n,\", prior_args, \")\") ) )\n    \n    # plotting the prior in the log-odds scale\n    dens(sim, col = \"steelblue\", lwd = 2, main = prior, xlab = \"log-odds\")\n    \n    # plotting the prior in the probability scale\n    dens(plogis(sim), col = \"steelblue\", lwd = 2, main = prior, xlab = \"probability\")\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2) )\nprior_scales(prior = \"norm(0,5)\")\nprior_scales(prior = \"halfcauchy(5)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAs we can see, in the weird logit world, the `normal` and `halfcauchy` priors tend to favour extreme values. To prevent this, McElreath (2016, page 363) suggests to use `exponential` priors for the variance components, instead of the `normal` or `halfcauchy` priors.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow = c(1, 2) )\nprior_scales(prior = \"exp(2)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe model with the exponential prior can be fitted easily with `brms`, as follows.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(brms)\n\nprior1 <- c(\n    prior(normal(0, 5), class = Intercept, coef = \"\"),\n    prior(normal(0, 5), class = b, coef = \"gender\"),\n    prior(exponential(2), class = sd) )\n\nmodel1 <- brm(\n    admit | trials(applications) ~ 1 + gender + (1 | dept_id),\n    family = binomial(link = \"logit\"),\n    prior = prior1,\n    data = data,\n    iter = 1e3,\n    cores = parallel::detectCores(),\n    control = list(adapt_delta = 0.95)\n    )\n```\n:::\n\n\nWe can easily obtain a summary of the model as follows:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(model1, parameters = c(\"^b_\", \"^sd_\"), prob = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: binomial \n  Links: mu = logit \nFormula: admit | trials(applications) ~ 1 + gender + (1 | dept_id) \n   Data: data (Number of observations: 12) \n  Draws: 4 chains, each with iter = 1000; warmup = 500; thin = 1;\n         total post-warmup draws = 2000\n\nMultilevel Hyperparameters:\n~dept_id (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.18      0.32     0.71     1.94 1.01      415      732\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -0.64      0.50    -1.61     0.32 1.02      362      641\ngender       -0.09      0.08    -0.25     0.07 1.01      952      694\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nAs [previously](http://www.barelysignificant.com/absenteeism2/), we can interpret the variation of the intercept $\\alpha$ between departments by considering the ICC, which goes from 0 if the grouping conveys no information to 1 if all levels of a cluster are identical (Gelman, 2006, p. 258). In other words, ICC = 0 indicates perfect independence of residuals: the observations do not depend on cluster membership. When the ICC is not different from zero or negligible, one could consider running traditional one-level regression analysis. On the contrary, ICC = 1 indicates perfect interdependence of residuals: the observations only vary between clusters (Sommet & Morselli, 2017).\n\n## What is the problem?\n\nThe ICC is usually expressed as $\\dfrac{\\tau^{2}}{\\tau^{2} + \\sigma^{2}}$, where $\\tau^2$ denotes the variance of the distribution of the varying effects, and $\\sigma^{2}$ the variance of the residuals. However, in the context of logistic regression, there is no direct estimation of the residuals $\\sigma^2$ on the first level. Unlike in the normal case, the level 1 variance depends on the expected value, as $var(p_{ij}) = p_{ij}(1-p_{ij})$, and the fixed predictor in the model depends on the value of `gender`. Therefore, as we are considering a function of the predictor variable `gender`, a simple ICC is not available, even though there is only a single level 2 variance. Furthermore, the level 2 variance is measured on the logistic scale and so is not directly comparable to the level 1 variance (Goldstein, 2010).\n\nIn the following, we consider three different approaches to approximate the ICC. Basically, these procedures convert both the between-cluster and the within-cluster variances to the same scale, to allows the subsequent computation of the ICC.\n\n## Method 1: The latent variable approach\n\nThe latent variable approach considers the observed binary response to represent a thresholded continuous variable where we observe 0 below the threshold and 1 above.\n\nIn a logit model we have an underlying logistic distribution for such a variable. We know that the [logistic distribution](https://en.wikipedia.org/wiki/Logistic_distribution) has variance $\\pi^{2} / 3 = 3.29$. We can then take this as the level 1 variance so that now both the level 1 and 2 variances are on the same scale. From there, the ICC is given by the simple formula $\\dfrac{\\tau^{2}}{\\tau^{2} + \\frac{\\pi^2}{3}}$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# extracting tau^2 for the varying intercept\ntau2 <- brms::VarCorr(model1)[[1]]$sd[1]^2\n\n# computing the ICC for the intercept\nICC1 <- tau2 / (tau2 + (pi^2 / 3) )\nICC1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2973733\n```\n\n\n:::\n:::\n\n\nNote though that when there are predictors in the model, the ICC should have a conditional interpretation: of the residual variation in outcomes that remains after accounting for the variables in the model, it is the proportion that is attributable to systematic differences between clusters (i.e., in our example between departments).\n\nGoldstein et al. (2002) suggest that the above approach to evaluating the ICC is only appropriate when the binary response can be conceptualized as the discretization of an underlying continuous latent variable (e.g., pass/fail on a test is a binary representation of an underlying continuous latent variable denoting the test score). For a binary outcome such as mortality, they suggest that such an assumption may not be warranted as it is unobservable[^1].\n\nOn the other hand, one can assume that there is an underlying propensity of dying and that an individual dies when he/she reaches a certain threshold... However, Goldstein et al. (2002) described a simulation-based approach that does not require this assumption, and that we will present in the next section.\n\n## Method 2: Simulation\n\nWhile very useful, a characteristic of this simulation-based approach is that it is dependent on specific covariate patterns. Thus, one could conceivably have a different value of the ICC for each distinct covariate pattern (this could be of substantive interest in and of itself). In the following example, we then compute the ICC for every value of the `gender` predictor, that is for females and for males. The proposed algorithm is as follows.\n\n* Simulate a large number $N$ of varying effects from the varying effects distribution that was estimated by the multilevel logistic regression model: $\\alpha_{dept} \\sim \\mathrm{Normal}(\\alpha, \\tau)$.\n\n* For a specific covariate pattern (i.e., for a particular chosen value of `gender`), use each of the simulated random effects drawn previously to compute the predicted probability $p_{ij}$ of the outcome. For each of these computed probabilities, compute the Level 1 variance: $v_{ij}=p_{ij}(1-p_{ij})$.\n\n* The ICC is then evaluated as: $\\dfrac{Var(p_{ij})}{Var(p_{ij})+\\frac{1}{N}\\sum_{i=1}^{N}v_{ij}}$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# extracting the model estimates\nest <- brms::fixef(model1)[,1]\n\n# starting from hell\nset.seed(666)\n# number of simulations\nN <- 1e5\n\n# drawing varying effects from the estimated distribution of varying effects\na_dpt <- rnorm(N, mean = est[1], sd = sqrt(tau2) )\n\n# computing the ICC for females\n# probability of the outcome\npA <- exp(a_dpt + est[2] * -0.5) / (1 + exp(a_dpt + est[2] * -0.5) )\n# compute the Bernoulli level-1 residual variance\nvA <- pA * (1 - pA)\n# mean of Bernoulli variances\nsA <- mean(vA)\n# compute the ICC\nICC2.f <- var(pA) / (var(pA) + sA)\n\n# computing the ICC for males\n# probability of the outcome\npA <- exp(a_dpt + est[2] * 0.5) / (1 + exp(a_dpt + est[2] * 0.5) )\n# compute the Bernoulli level-1 residual variance\nvA <- pA * (1 - pA)\n# mean of Bernoulli variances\nsA <- mean(vA)\n# compute the ICC\nICC2.m <- var(pA) / (var(pA) + sA)\n\nc(ICC2.f, ICC2.m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2118767 0.2100947\n```\n\n\n:::\n:::\n\n\nWe see that this method provides estimates slightly inferior to the latent variable approach, and indicates no noticeable differences between females and males.\n\n## Method 3: Model linearisation (from Goldstein, Browne, & Rasbah, 2002)\n\nRecall that we try to estimate here the probability of admission $p_{ij}$. Using a first order Taylor expansion (e.g., Goldstein & Rasbash, 1996; Goldstein, 2010), we can rewrite our model and evaluate $p_{ij}$ at the mean of the distribution of the level 2 varying effect, that is, for the logistic model\n\n$$p_{ij}=\\exp(\\alpha+\\beta\\times gender_{i}) /(1+\\exp(\\alpha+\\beta\\times gender_{i}))$$\n\nso that we have\n\n$$var(y_{ij}|gender_{i})=\\tau^{2}p_{ij}^2([1+\\exp(\\alpha+\\beta\\times gender_{i})]^{-2}+p_{ij}(1-p_{ij})$$\nand\n\n$$\\text{ICC}=\\dfrac{\\tau^{2}p_{ij}^2([1+\\exp(\\alpha+\\beta\\times gender_{i})]^{-2}}{\\tau^{2}p_{ij}^{2}[1+\\exp(\\alpha+\\beta\\times gender_{i})]^{-2}+p_{ij}(1-p_{ij})}$$\n\nBelow, we use this method to evaluate the ICC for both females (i.e., `gender=-0.5`) and males (i.e., `gender=0.5`).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# evaluating pi at the mean of the distribution of the level 2 varying effect\np <- exp(est[1] + est[2] * -0.5) / (1 + exp(est[1] + est[2] * -0.5) )\n# computing var(p)\nsig1 <- p * (1 - p)\n# computing var(yij)\nsig2 <- tau2 * p^2 * (1 + exp(est[1] + est[2] * -0.5) )^(-2)\n# computing the ICC\nICC3.f <- sig2 / (sig1 + sig2)\n\n# evaluating pi at the mean of the distribution of the level 2 varying effect\np <- exp(est[1] + est[2] * 0.5) / (1 + exp(est[1] + est[2] * 0.5) )\n# computing pi'\nsig1 <- p * (1 - p)\n# computing var(yij)\nsig2 <- tau2 * p^2 * (1 + exp(est[1] + est[2] * 0.5) )^(-2)\n# computing the ICC\nICC3.m <- sig2 / (sig1 + sig2)\n\nc(ICC3.f, ICC3.m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIntercept Intercept \n0.2420874 0.2369956 \n```\n\n\n:::\n:::\n\n\nHere again, the amount of variation by department seem to be similar for both females and males. Below we summarise the results of the three methods.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover table-responsive\" style=\"color: black; width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> method 1 </th>\n   <th style=\"text-align:right;\"> method 2 </th>\n   <th style=\"text-align:right;\"> method 3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> ICC </td>\n   <td style=\"text-align:right;\"> 0.2973733 </td>\n   <td style=\"text-align:right;\"> 0.2118767 </td>\n   <td style=\"text-align:right;\"> 0.2420874 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Conclusions\n\nNow that you reached the end of this post, I should confess that there exists packages out there that implement these three methods, and even more. The `icc` function in the `sjstats` package allow to compute the ICC for models fitted with `lme4`, while the `ICCbin` package offer 16 different methods to compute the ICC for binary responses. The `iccbin` function of the `aod` package implements three of the four methods described by Goldstein et al. (2002).\n\nIn conclusion, it is interesting to note that the VPC and the ICC cease to be the same thing if we allow the slope to vary (Goldstein et al., 2002). We can find more on this topic in Kreft & De Leeuw (1998, page 63):\n\n> \"The concept of intra-class correlation is based on a model with a random intercept only. No unique intra-class correlation can be calculated when a random slope is present in the model. The value of the between variance in models with a random slope and a random intercept is a combination of slope and intercept variance (and covariance). We know from the discussion of the basic RC model that the variance of the slope (and, as a consequence, the value of the covariance) is related to the value of the explanatory variable x. Thus the intra-class correlation between individuals will be different, in models with random slopes, for individuals with different x-values. As a result the intra-class correlation is no longer uniquely defined\".\n\nBut maybe we should keep this for a future post.\n\n## References\n\n<details>\n  <summary>Click to expand</summary>\n\n<div markdown=\"1\">\n\nAustin, P. C., & Merlo, J. (2017). Intermediate and advanced topics in multilevel logistic regression analysis. *Statistics in Medicine, 36*, 3257-3277.\n\nBürkner, P.-C. (2017). brms: An R Package for Bayesian Multilevel Models Using Stan. *Journal of Statistical Software, 80*(1), 1-28. doi:10.18637/jss.v080.i01\n\nGoldstein, H. and Rasbash, J. (1996). Improved approximations for multilevel models with binary responses. *Journal of the Royal Statistical Society*, A. 159: 505-13.\n\nGoldstein, H., Browne, W., & Rasbash, J. (2002). Partitioning variation in generalised linear multilevel models. *Understanding Statistics*, 1:223–232.\n\nGoldstein, H. (2010). Multilevel Statistical Models, 4th Edition. John Wiley & Sons, Ltd, Chichester, UK.\n\nMcElreath, R. (2016). Statistical Rethinking. Chapman; Hall/CRC.\n\nSnijders, T., & Bosker, R. (1999). Multilevel Analysis. Sage.\n\n</div>\n\n</details>\n\n[^1]: See also Snijders and Bosker (1999, Chapter 14) for a further discussion.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}