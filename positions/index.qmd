---
title: Open positions
# excerpt: "Open positions in my team"
# toc-location: right
---

If you are interested in joining my team within the [LPL (CNRS UMR 7309)](https://www.lpl-aix.fr/en/lab/) in [Aix-en-Provence](https://en.wikipedia.org/wiki/Aix-en-Provence) (France) as a Master's student, PhD student, or postdoctoral researcher, feel free to [contact me](mailto:ladislas.nalborczyk@cnrs.fr) at any time, even if no open position matching your profile is currently advertised.

---

## Postdoctoral positions

There are currently no officially announced postdoctoral positions, but feel free to contact me at any time to inquire about opportunities. For instance, if you are currently working out of France, you could consider applying to a [MSCA postdoc grant](https://marie-sklodowska-curie-actions.ec.europa.eu/actions/postdoctoral-fellowships) (deadline: around September every year) or a [Fyssen postdoc grant](https://www.fondationfyssen.fr/en/study-grants/aim-award/) (deadline: around March every year) in my team.

## PhD positions

There are currently no officially announced PhD positions, but feel free to contact me at any time to inquire about opportunities.

## Master's degree research internships

::: {.callout-note icon=false collapse="true"}
## Uncovering the neural dynamics of inner speech from EEG signals (5-6 months)

**Supervision**: [Ladislas Nalborczyk](../team#ladislas){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

**Project description**: The mental production of speech or "inner speech" is a cornerstone of human cognition. It is involved in a plethora of activities such as reading, writing, planning, or remembering. Inner speech is generally accompanied by a rich subjective multisensory experience featuring most notably auditory percepts (the "inner voice"). Despite the ubiquity of this inner voice, the cognitive and neural mechanisms leading to this subjective experience remain poorly known. One prominent perspective is that the sensory content of inner speech would correspond to the predicted sensory consequences of inhibited speech acts. However, the precise timecourse of each sub-process is unknown. The main objective of this project is to test core predictions of the mental simulation perspective on inner speech and to delineate its timecourse. To this end, we will use time-resolved MVPA (aka "decoding") to reanalyse an existing EEG dataset of overt and covert (inner) speech production.

**Project structure**:

- Understanding the problem (literature work on inner speech and multivariate pattern analysis)
- Implementing (from partially existing code) and performing individual-level and group-level analyses (in Python using MNE-Python)
- Discussing the results and writing a report (thesis)

**Key references**: 

- King, J.-R., & Dehaene, S. (2014). Characterizing the dynamics of mental representations: The temporal generalization method. Trends in Cognitive Sciences, 18(4), 203–210. <https://doi.org/10.1016/j.tics.2014.01.002>
- Lœvenbruck, H., Grandchamp, R., Rapin, L., Nalborczyk, L., Dohen, M., Perrier, P., Baciu, M., & Perrone-Bertolotti, M. (2018). A cognitive neuroscience view of inner language: To predict and to hear, see, feel. In P. Langland-Hassan & A. Vicente (Eds.), Inner speech: New voices (p. 37). Oxford University Press.

**Computer tools**: Python, MNE-Python, scikit-learn, MVPA

**Key-words**: Cognitive Neuroscience, Electroencephalography
:::

::: {.callout-note icon=false collapse="true"}
## Does the corollary discharge provide the sensory content of inner speech? (5-6 months)

**Supervision**: [Ladislas Nalborczyk](../team#ladislas){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

**Project description**: The mental production of speech or "inner speech" is a remarkable and foundational ability in humans, involved in a plethora of activities such as reading, writing, planning, or remembering. Inner speech is generally accompanied by a subjective multisensory experience featuring most notably auditory percepts (the "inner voice"). Despite the ubiquity of this inner voice, the cognitive and neural mechanisms leading to this rich subjective experience remain poorly known. One prominent perspective is that the auditory content of inner speech would correspond to the predicted sensory consequences of inhibited speech acts. The study conducted by Scott (2013) provided one of the few pieces of experimental evidence suggesting that inner speech indeed involves a mental simulation of speech motor commands, as evidenced by sensory attenuation of the concomitant (and congruent) perception of external speech sounds during inner speech. Although being widely cited in the inner speech literature, one major limitation of this study is that it does not assess inner speech, but rather what is commonly referred to as silent speech, which is the mouthed but silent production of speech (i.e., speech produced with visible articulatory movements, but without phonation). Inner speech, on the other hand, does not involve visible articulatory movements. Therefore, we aim to replicate this study with a larger sample of participants and, crucially, by adding a proper inner speech condition. The protocol for this study has already been "in-principle accepted" as a registered report.

**Project structure**:

- Understanding the problem (literature work on inner speech and internal models)
- Implementing the experiment (from partially existing code) in Python/PsychoPy
- Collecting the behavioural data
- Analysing the behavioural data (in R)
- Discussing the results and writing a report (thesis)

**Key references**: 

- Delem, M., Stauffert, N., Nguyen, N., Debarnot, U., Guillot, A., & Nalborczyk, L. (2024, in-principle accepted as a Stage-1 registered report). Does the corollary discharge provide the sensory content of inner speech? A preregistered direct replication and extension of Scott  (2013). <https://doi.org/10.31234/osf.io/abps9>
- Scott, M. (2013). Corollary Discharge Provides the Sensory Content of Inner Speech. Psychological Science, 24(9), 1824–1830. <https://doi.org/10.1177/0956797613478614>
- Lœvenbruck, H., Grandchamp, R., Rapin, L., Nalborczyk, L., Dohen, M., Perrier, P., Baciu, M., & Perrone-Bertolotti, M. (2018). A cognitive neuroscience view of inner language: To predict and to hear, see, feel. In P. Langland-Hassan & A. Vicente (Eds.), Inner speech: New voices (p. 37). Oxford University Press.

**Computer tools**: R, Python, PsychoPy

**Key-words**: Experimental Psychology, Psycholinguistics
:::

::: {.callout-note icon=false collapse="true"}
## Modelling the onset and duration of imagined actions (5-6 months)

**Supervision**: [Ladislas Nalborczyk](../team#ladislas){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

**Project description**: The ability to mentally prepare, simulate, or withhold actions is crucial to smooth motor execution. Whereas motor imagery has been shown to overlap with motor execution in terms of functional consequences and neural implementation, the lack of a precise description of the mechanisms involved in motor imagery has hindered better understanding of this ubiquitous phenomenon. To fill this gap, we developed an algorithmic model of motor imagery able to simulate the onset and duration of imagined actions. This model provides a simplified overarching description of how the motor system is involved over time during motor imagery and allows separating the influence of distinct inhibitory mechanisms during motor imagery. We assessed the recoverability of the model's parameters with more than satisfactory results and validated its predictions against available data from the literature. In addition to providing an excellent fit to these data, interpreting parameters from this model allowed us disentangling multiple inhibitory mechanisms at play during motor imagery, with distinct behavioural consequences. The objective of this research project is to further test some assumptions and predictions of this model using both novel empirical data and simulations.

**Project structure**:

- Understanding the problem (literature work on motor imagery and cognitive modelling)
- Implementing the experiment (from partially existing code) in Python/PsychoPy
- Collecting the behavioural data AND/OR performing a simulation study
- Analysing the behavioural data (in R) AND/OR analysing the model's simulated data
- Discussing the results and writing a report (thesis)

**Key references**: 

- Guillot, A., Di Rienzo, F., MacIntyre, T., Moran, A., & Collet, C. (2012). Imagining is not doing but involves specific motor commands: A review of experimental data related to motor inhibition. *Frontiers in Human Neuroscience, 6, 141*. <https://doi.org/10.3389/fnhum.2012.00247>
- Jeannerod, M. (2001). Neural simulation of action: A unifying mechanism for motor cognition. *NeuroImage, 14*(1), S103–S109. <https://doi.org/10.1006/nimg.2001.0832>
- Nalborczyk, L., Longcamp, M., Gajdos, T., Servant, M., & Alario, F.X. (2024). Towards formal models of inhibitory mechanisms involved in motor imagery: a commentary on Bach et al. (2022). *Psychological Research 88*, 1810–1813. <https://doi.org/10.1007/s00426-023-01915-8>

**Computer tools**: R, Python, PsychoPy

**Key-words**: Experimental Psychology, Cognitive Neuroscience, Cognitive Modelling
:::

::: {.callout-note icon=false collapse="true"}
## Mental imagery: what are vividness ratings made of? (5-6 months)

**Supervision**: [Ladislas Nalborczyk](../team#ladislas){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

**Project description**: How do people judge the vividness of what they imagine? Mental imagery tasks routinely rely on subjective vividness ratings, yet we know surprisingly little about what drives these ratings. Beyond perceptual qualities, vividness judgements may partly reflect the semantic content of the imagined item; specifically, how informative, specific, or unique the described item is in relation to the world. Recent advances in natural language processing allow quantifying this "semantic specificity" using language models and text–to-image models. The aim of this project is to determine whether subjective vividness ratings are systematically biased by the semantic informativeness of the items used in mental imagery experiments. By applying these analyses to existing behavioural datasets, this project will shed new light on the cognitive foundations of vividness judgements and contribute to a more mechanistic understanding of mental imagery.

**Project structure**:

- Understanding the problem (literature work on mental imagery)
- Implementing the analyses in Python
- Discussing the results and writing a report (thesis)

**Computer tools**: Python, R

**Key-words:** Mental Imagery, Cognitive Neuroscience, Natural Language Processing
:::

::: {.callout-note icon=false collapse="true"}
## Multilevel Bayesian modelling of M/EEG data (5-6 months)

**Supervision**: [Ladislas Nalborczyk](../team#ladislas){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs} in collaboration with [Paul Bürkner](https://paulbuerkner.com)

**Project description**: Recent work has shown that Bayesian Generalised Additive Multilevel Models (BGAMMs) provide a powerful and principled alternative to cluster-based permutation tests for analysing M/EEG data, as they naturally account for temporal dependencies, yield smooth time courses of effects, and allow both participant- and group-level inference. Building on our recent paper, the goal of this internship is to extend this modelling framework to the spatiotemporal domain by incorporating sensor-level structure (e.g., adjacency matrices, spatial bases, covariance kernels) into the multilevel Bayesian model. A central challenge is to design a method that remains computationally efficient, scalable to high-dimensional M/EEG datasets, and compatible with practical workflows in MNE-Python and R. The student will work on model development, simulation studies, and empirical applications using real M/EEG datasets.

**Project structure**:

- Reviewing statistical approaches for modelling temporal and spatial dependencies in M/EEG data
- Developing a spatiotemporal Bayesian GAMM (e.g., tensor-product smooths, sparse or low-rank spatial bases, adjacency-informed priors)
- Implementing computationally efficient inference (e.g., reduced-rank smooths, variational Bayes, efficient basis selection)
- Running extensive simulation studies to assess recoverability, speed, and accuracy
- Applying the model to real M/EEG data and comparing it with classical permutation-based statistics
- Writing the thesis and documenting the modelling framework

**Student profile**

Master student in statistics, informatics, data science, computational statistics, or applied mathematics. Strong interest in Bayesian modelling and numerical optimisation. Experience with R and/or Python is recommended.

**Key references**: 

- Nalborczyk, L. & Bürkner, P. (2025). Precise temporal localisation of M/EEG effects with Bayesian generalised additive multilevel models. bioRxiv. <https://www.biorxiv.org/content/10.1101/2025.08.29.672336>
- Wood, S. N. (2017). Generalized Additive Models: An Introduction with R (2nd edition).

**Computer tools**: R, Python

**Key-words**: Bayesian Modelling, Computational Statistic, M/EEG
:::
